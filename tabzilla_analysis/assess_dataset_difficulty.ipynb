{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from metadata_utils import get_metadata, get_tuned_alg_perf, process_metafeatures, compute_feature_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/tabzilla/tabzilla_analysis/metadata_utils.py:56: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  metafeatures_processed = metafeatures_df.fillna(metafeatures_df.median())\n"
     ]
    }
   ],
   "source": [
    "# read tuned results dataset\n",
    "tuned_agg_df = pd.read_csv(\"./results/tuned_aggregated_results.csv\")\n",
    "\n",
    "# read dataset meta-features\n",
    "dataset_version = \"\"\n",
    "\n",
    "# For choosing metafeatures\n",
    "filter_families = [\n",
    "    'general',\n",
    "    'statistical',\n",
    "    'info-theory'\n",
    "]\n",
    "\n",
    "_, metafeatures_df = get_metadata(dataset_version)\n",
    "\n",
    "metafeatures_processed = process_metafeatures(metafeatures_df, filter_families=filter_families)\n",
    "metafeatures_df = metafeatures_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>alg_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>Accuracy__test_median</th>\n",
       "      <th>Accuracy__test_mean</th>\n",
       "      <th>time__train_median</th>\n",
       "      <th>time__train_mean</th>\n",
       "      <th>dataset_name_count</th>\n",
       "      <th>Accuracy__test_mean_min</th>\n",
       "      <th>Accuracy__test_mean_max</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_F1__test_mean</th>\n",
       "      <th>F1_rank_mean</th>\n",
       "      <th>F1_rank_median</th>\n",
       "      <th>Log Loss__test_median</th>\n",
       "      <th>Log Loss__test_mean</th>\n",
       "      <th>Log Loss__test_mean_min</th>\n",
       "      <th>Log Loss__test_mean_max</th>\n",
       "      <th>normalized_Log Loss__test_mean</th>\n",
       "      <th>Log Loss_rank_mean</th>\n",
       "      <th>Log Loss_rank_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>0.994145</td>\n",
       "      <td>0.994013</td>\n",
       "      <td>6.412328</td>\n",
       "      <td>7.276401</td>\n",
       "      <td>10</td>\n",
       "      <td>0.970303</td>\n",
       "      <td>0.994500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979880</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.018329</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0.017652</td>\n",
       "      <td>0.624879</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__Amazon_employee_access__34539</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.947359</td>\n",
       "      <td>1.708439</td>\n",
       "      <td>1.729567</td>\n",
       "      <td>10</td>\n",
       "      <td>0.930422</td>\n",
       "      <td>0.951570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800861</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.156969</td>\n",
       "      <td>0.156347</td>\n",
       "      <td>0.155615</td>\n",
       "      <td>0.364447</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__Australian__146818</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.872464</td>\n",
       "      <td>1.347650</td>\n",
       "      <td>1.393643</td>\n",
       "      <td>10</td>\n",
       "      <td>0.711594</td>\n",
       "      <td>0.872464</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.290150</td>\n",
       "      <td>0.302677</td>\n",
       "      <td>0.302677</td>\n",
       "      <td>0.755920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__Bioresponse__9910</td>\n",
       "      <td>0.798940</td>\n",
       "      <td>0.795521</td>\n",
       "      <td>5.815126</td>\n",
       "      <td>6.748842</td>\n",
       "      <td>10</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>0.796848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977987</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.455072</td>\n",
       "      <td>0.456102</td>\n",
       "      <td>0.451718</td>\n",
       "      <td>0.767631</td>\n",
       "      <td>0.013877</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__Census-Income__168340</td>\n",
       "      <td>0.958869</td>\n",
       "      <td>0.958658</td>\n",
       "      <td>830.825629</td>\n",
       "      <td>857.921920</td>\n",
       "      <td>10</td>\n",
       "      <td>0.945370</td>\n",
       "      <td>0.958658</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.109673</td>\n",
       "      <td>0.109425</td>\n",
       "      <td>0.109108</td>\n",
       "      <td>0.268570</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  alg_name                           dataset_name  \\\n",
       "0           0  CatBoost             openml__APSFailure__168868   \n",
       "1           1  CatBoost  openml__Amazon_employee_access__34539   \n",
       "2           2  CatBoost             openml__Australian__146818   \n",
       "3           3  CatBoost              openml__Bioresponse__9910   \n",
       "4           4  CatBoost          openml__Census-Income__168340   \n",
       "\n",
       "   Accuracy__test_median  Accuracy__test_mean  time__train_median  \\\n",
       "0               0.994145             0.994013            6.412328   \n",
       "1               0.946903             0.947359            1.708439   \n",
       "2               0.869565             0.872464            1.347650   \n",
       "3               0.798940             0.795521            5.815126   \n",
       "4               0.958869             0.958658          830.825629   \n",
       "\n",
       "   time__train_mean  dataset_name_count  Accuracy__test_mean_min  \\\n",
       "0          7.276401                  10                 0.970303   \n",
       "1          1.729567                  10                 0.930422   \n",
       "2          1.393643                  10                 0.711594   \n",
       "3          6.748842                  10                 0.736600   \n",
       "4        857.921920                  10                 0.945370   \n",
       "\n",
       "   Accuracy__test_mean_max  ...  normalized_F1__test_mean  F1_rank_mean  \\\n",
       "0                 0.994500  ...                  0.979880           3.0   \n",
       "1                 0.951570  ...                  0.800861           4.0   \n",
       "2                 0.872464  ...                  1.000000           1.0   \n",
       "3                 0.796848  ...                  0.977987           2.0   \n",
       "4                 0.958658  ...                  1.000000           1.0   \n",
       "\n",
       "   F1_rank_median  Log Loss__test_median  Log Loss__test_mean  \\\n",
       "0             2.0               0.018329             0.018939   \n",
       "1             3.0               0.156969             0.156347   \n",
       "2             2.0               0.290150             0.302677   \n",
       "3             1.0               0.455072             0.456102   \n",
       "4             1.0               0.109673             0.109425   \n",
       "\n",
       "   Log Loss__test_mean_min  Log Loss__test_mean_max  \\\n",
       "0                 0.017652                 0.624879   \n",
       "1                 0.155615                 0.364447   \n",
       "2                 0.302677                 0.755920   \n",
       "3                 0.451718                 0.767631   \n",
       "4                 0.109108                 0.268570   \n",
       "\n",
       "   normalized_Log Loss__test_mean  Log Loss_rank_mean  Log Loss_rank_median  \n",
       "0                        0.002121                 3.0                   2.0  \n",
       "1                        0.003507                 2.0                   2.0  \n",
       "2                        0.000000                 1.0                   1.0  \n",
       "3                        0.013877                 3.0                   1.0  \n",
       "4                        0.001986                 2.0                   2.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_agg_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>f__pymfe.general.attr_to_inst</th>\n",
       "      <th>f__pymfe.general.cat_to_num</th>\n",
       "      <th>f__pymfe.general.freq_class.count</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.0</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.1</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.2</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.3</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.4</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.5</th>\n",
       "      <th>...</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.quantiles.1</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.quantiles.2</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.quantiles.3</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.quantiles.4</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.range</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.sd</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.skewness</th>\n",
       "      <th>f__pymfe.info-theory.ns_ratio</th>\n",
       "      <th>f__pymfe.statistical.iq_range</th>\n",
       "      <th>f__pymfe.statistical.t_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openml__cjs__14967__fold_0</td>\n",
       "      <td>0.014758</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679330</td>\n",
       "      <td>1.292908</td>\n",
       "      <td>1.906486</td>\n",
       "      <td>2.520065</td>\n",
       "      <td>2.454313</td>\n",
       "      <td>1.735461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.325505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openml__cjs__14967__fold_1</td>\n",
       "      <td>0.014758</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677179</td>\n",
       "      <td>1.291474</td>\n",
       "      <td>1.905769</td>\n",
       "      <td>2.520065</td>\n",
       "      <td>2.457180</td>\n",
       "      <td>1.737489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.336153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openml__cjs__14967__fold_2</td>\n",
       "      <td>0.014758</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684753</td>\n",
       "      <td>1.296524</td>\n",
       "      <td>1.908294</td>\n",
       "      <td>2.520065</td>\n",
       "      <td>2.447082</td>\n",
       "      <td>1.730348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.327456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openml__cjs__14967__fold_3</td>\n",
       "      <td>0.014758</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688757</td>\n",
       "      <td>1.299327</td>\n",
       "      <td>1.909898</td>\n",
       "      <td>2.520468</td>\n",
       "      <td>2.442282</td>\n",
       "      <td>1.726954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.313806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openml__cjs__14967__fold_4</td>\n",
       "      <td>0.014758</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681562</td>\n",
       "      <td>1.294577</td>\n",
       "      <td>1.907592</td>\n",
       "      <td>2.520608</td>\n",
       "      <td>2.452061</td>\n",
       "      <td>1.733869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.322964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 651 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dataset_name  f__pymfe.general.attr_to_inst  \\\n",
       "0  openml__cjs__14967__fold_0                       0.014758   \n",
       "1  openml__cjs__14967__fold_1                       0.014758   \n",
       "2  openml__cjs__14967__fold_2                       0.014758   \n",
       "3  openml__cjs__14967__fold_3                       0.014758   \n",
       "4  openml__cjs__14967__fold_4                       0.014758   \n",
       "\n",
       "   f__pymfe.general.cat_to_num  f__pymfe.general.freq_class.count  \\\n",
       "0                     0.064516                                  6   \n",
       "1                     0.064516                                  6   \n",
       "2                     0.064516                                  6   \n",
       "3                     0.064516                                  6   \n",
       "4                     0.064516                                  6   \n",
       "\n",
       "   f__pymfe.general.freq_class.histogram.0  \\\n",
       "0                                 0.166667   \n",
       "1                                 0.166667   \n",
       "2                                 0.166667   \n",
       "3                                 0.166667   \n",
       "4                                 0.166667   \n",
       "\n",
       "   f__pymfe.general.freq_class.histogram.1  \\\n",
       "0                                 0.166667   \n",
       "1                                 0.166667   \n",
       "2                                 0.166667   \n",
       "3                                 0.166667   \n",
       "4                                 0.166667   \n",
       "\n",
       "   f__pymfe.general.freq_class.histogram.2  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "\n",
       "   f__pymfe.general.freq_class.histogram.3  \\\n",
       "0                                 0.166667   \n",
       "1                                 0.166667   \n",
       "2                                 0.166667   \n",
       "3                                 0.166667   \n",
       "4                                 0.166667   \n",
       "\n",
       "   f__pymfe.general.freq_class.histogram.4  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "\n",
       "   f__pymfe.general.freq_class.histogram.5  ...  \\\n",
       "0                                 0.166667  ...   \n",
       "1                                 0.166667  ...   \n",
       "2                                 0.166667  ...   \n",
       "3                                 0.166667  ...   \n",
       "4                                 0.166667  ...   \n",
       "\n",
       "   f__pymfe.info-theory.mut_inf.quantiles.1  \\\n",
       "0                                  0.679330   \n",
       "1                                  0.677179   \n",
       "2                                  0.684753   \n",
       "3                                  0.688757   \n",
       "4                                  0.681562   \n",
       "\n",
       "   f__pymfe.info-theory.mut_inf.quantiles.2  \\\n",
       "0                                  1.292908   \n",
       "1                                  1.291474   \n",
       "2                                  1.296524   \n",
       "3                                  1.299327   \n",
       "4                                  1.294577   \n",
       "\n",
       "   f__pymfe.info-theory.mut_inf.quantiles.3  \\\n",
       "0                                  1.906486   \n",
       "1                                  1.905769   \n",
       "2                                  1.908294   \n",
       "3                                  1.909898   \n",
       "4                                  1.907592   \n",
       "\n",
       "   f__pymfe.info-theory.mut_inf.quantiles.4  \\\n",
       "0                                  2.520065   \n",
       "1                                  2.520065   \n",
       "2                                  2.520065   \n",
       "3                                  2.520468   \n",
       "4                                  2.520608   \n",
       "\n",
       "   f__pymfe.info-theory.mut_inf.range  f__pymfe.info-theory.mut_inf.sd  \\\n",
       "0                            2.454313                         1.735461   \n",
       "1                            2.457180                         1.737489   \n",
       "2                            2.447082                         1.730348   \n",
       "3                            2.442282                         1.726954   \n",
       "4                            2.452061                         1.733869   \n",
       "\n",
       "   f__pymfe.info-theory.mut_inf.skewness  f__pymfe.info-theory.ns_ratio  \\\n",
       "0                                    0.0                       2.325505   \n",
       "1                                    0.0                       2.336153   \n",
       "2                                    0.0                       2.327456   \n",
       "3                                    0.0                       2.313806   \n",
       "4                                    0.0                       2.322964   \n",
       "\n",
       "   f__pymfe.statistical.iq_range  f__pymfe.statistical.t_mean  \n",
       "0                            NaN                          NaN  \n",
       "1                            NaN                          NaN  \n",
       "2                            NaN                          NaN  \n",
       "3                            NaN                          NaN  \n",
       "4                            NaN                          NaN  \n",
       "\n",
       "[5 rows x 651 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metafeatures_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize each alg\n",
    "\n",
    "neural_algs = [\n",
    "    \"MLP\",\n",
    "    \"TabNet\",\n",
    "    \"VIME\",\n",
    "    \"TabTransformer\",\n",
    "    \"NODE\",\n",
    "    \"STG\",\n",
    "    \"NAM\",\n",
    "    \"DeepFM\",\n",
    "    \"SAINT\",\n",
    "    \"DANet\",\n",
    "    \"rtdl_MLP\",\n",
    "    \"rtdl_ResNet\",\n",
    "    \"rtdl_FTTransformer\",\n",
    "]\n",
    "\n",
    "tree_algs = [\n",
    "    \"LightGBM\",\n",
    "    \"XGBoost\",\n",
    "    \"CatBoost\"\n",
    "]\n",
    "\n",
    "tuned_agg_df.loc[:, \"alg_type\"] = \"baseline\"\n",
    "tuned_agg_df.loc[tuned_agg_df[\"alg_name\"].isin(neural_algs), \"alg_type\"] = \"neural\"\n",
    "tuned_agg_df.loc[tuned_agg_df[\"alg_name\"].isin(tree_algs), \"alg_type\"] = \"trees\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alg_type  alg_name          \n",
       "baseline  DecisionTree          170\n",
       "          RandomForest          169\n",
       "          LinearModel           166\n",
       "          KNN                   163\n",
       "          SVM                   143\n",
       "neural    MLP                   169\n",
       "          TabNet                166\n",
       "          STG                   163\n",
       "          VIME                  162\n",
       "          NODE                  138\n",
       "          rtdl_MLP              133\n",
       "          DANet                 130\n",
       "          rtdl_ResNet           125\n",
       "          TabTransformer        122\n",
       "          DeepFM                 90\n",
       "          NAM                    79\n",
       "          SAINT                  77\n",
       "          rtdl_FTTransformer     37\n",
       "trees     XGBoost               170\n",
       "          LightGBM              163\n",
       "          CatBoost              162\n",
       "Name: alg_name, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_agg_df.groupby(\"alg_type\")[\"alg_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for which dataset does the best-performing baseline alg get at least 0.9 normalized metric?\n",
    "# best_performance_by_alg_type = tuned_agg_df.groupby([\"dataset_name\", \"alg_type\"])[\"normalized_F1__test_mean\"].max().reset_index()\n",
    "# best_performance_by_alg_type = tuned_agg_df.groupby([\"dataset_name\", \"alg_type\"])[\"normalized_Accuracy__test_mean\"].max().reset_index()\n",
    "best_performance_by_alg_type = tuned_agg_df.groupby([\"dataset_name\", \"alg_type\"])[\"normalized_Log Loss__test_mean\"].min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         dataset_name   Tree F1  \\\n",
      "0    openml__blood-transfusion-service-center__145836  0.790144   \n",
      "1                                  openml__musk__3950  1.000000   \n",
      "2                               openml__collins__3567  1.000000   \n",
      "3                 openml__visualizing_livestock__3731  0.853846   \n",
      "4                                 openml__irish__3543  1.000000   \n",
      "..                                                ...       ...   \n",
      "165                              openml__cnae-9__9981  0.734956   \n",
      "166                          openml__riccardo__168338  0.875250   \n",
      "167  openml__climate-model-simulation-crashes__146819  0.907407   \n",
      "168                             openml__semeion__9964  0.753620   \n",
      "169                              openml__isolet__3481  0.811161   \n",
      "\n",
      "     Tree F1 (normalized)    Min F1    Max F1  \n",
      "0                     1.0  0.754036  0.790144  \n",
      "1                     1.0  0.890420  1.000000  \n",
      "2                     1.0  0.383862  1.000000  \n",
      "3                     1.0  0.776923  0.853846  \n",
      "4                     1.0  0.664000  1.000000  \n",
      "..                    ...       ...       ...  \n",
      "165                   0.0  0.734956  0.954565  \n",
      "166                   0.0  0.875250  0.997350  \n",
      "167                   0.0  0.907407  0.957407  \n",
      "168                   0.0  0.753620  0.958529  \n",
      "169                   0.0  0.811161  0.973338  \n",
      "\n",
      "[170 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# order datasets by how well the decision tree model performs. also provide the range of metric for the dataset\n",
    "# metric = \"Log Loss\"\n",
    "metric = \"F1\"\n",
    "\n",
    "sorted_by_dt = tuned_agg_df[tuned_agg_df[\"alg_name\"] == \"DecisionTree\"] \\\n",
    "    .sort_values(f\"normalized_{metric}__test_mean\", \n",
    "        ignore_index=True,\n",
    "        ascending=False,\n",
    "    )[[\"dataset_name\",f\"{metric}__test_mean\", f\"normalized_{metric}__test_mean\", f\"{metric}__test_mean_min\", f\"{metric}__test_mean_max\"]]\n",
    "\n",
    "sorted_by_dt.rename(columns={\n",
    "    f\"{metric}__test_mean\": f\"Tree {metric}\",\n",
    "    f\"normalized_{metric}__test_mean\": f\"Tree {metric} (normalized)\",\n",
    "    f\"{metric}__test_mean_min\": f\"Min {metric}\",\n",
    "    f\"{metric}__test_mean_max\": f\"Max {metric}\"\n",
    "    }, inplace=True)\n",
    "\n",
    "sorted_by_dt.set_index(\"dataset_name\")\n",
    "# best_performance_by_alg_type[(best_performance_by_alg_type[\"alg_name\"] == \"DecisionTree\")]\n",
    "\n",
    "sorted_by_dt.to_csv(\"./results/hardness_tree_performance.csv\")\n",
    "print(sorted_by_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
