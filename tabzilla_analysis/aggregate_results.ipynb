{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run an initial analysis of results and produce aggregated results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display_html\n",
    "\n",
    "pd.options.display.max_rows = 400\n",
    "from metadata_utils import get_metadata, get_tuned_alg_perf, process_metafeatures, compute_feature_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/tabzilla/tabzilla_analysis/metadata_utils.py:56: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  metafeatures_processed = metafeatures_df.fillna(metafeatures_df.median())\n"
     ]
    }
   ],
   "source": [
    "dataset_version = \"\"\n",
    "\n",
    "# For choosing metafeatures\n",
    "filter_families = [\n",
    "    'general',\n",
    "    'statistical',\n",
    "    'info-theory'\n",
    "]\n",
    "\n",
    "metadataset_df, metafeatures_df = get_metadata(dataset_version)\n",
    "\n",
    "metafeatures_processed = process_metafeatures(metafeatures_df, filter_families=filter_families)\n",
    "metafeatures_df = metafeatures_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary            514200\n",
      "classification    378610\n",
      "Name: target_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# keep only binary and classification datasets\n",
    "print(metadataset_df[\"target_type\"].value_counts())\n",
    "\n",
    "metadataset_df = metadataset_df.loc[metadataset_df[\"target_type\"].isin([\"binary\", \"classification\"]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   dataset_fold_id\n",
      "alg_name    dataset_name                                          \n",
      "CatBoost    openml__APSFailure__168868                          10\n",
      "            openml__Amazon_employee_access__34539               10\n",
      "            openml__Australian__146818                          10\n",
      "            openml__Bioresponse__9910                           10\n",
      "            openml__Census-Income__168340                       10\n",
      "...                                                            ...\n",
      "rtdl_ResNet openml__vehicle__53                                 10\n",
      "            openml__visualizing_livestock__3731                 10\n",
      "            openml__vowel__3022                                 10\n",
      "            openml__wall-robot-navigation__9960                 10\n",
      "            openml__wdbc__9946                                  10\n",
      "\n",
      "[2937 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# check that all dataset-alg pairs have results for all 10 folds\n",
    "print(metadataset_df.groupby([\"alg_name\", \"dataset_name\"]).agg({\"dataset_fold_id\": lambda x: len(set(x))}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze num. results per dataset and alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each alg: number of datasets with results (out of 176)\n",
      "alg_name\n",
      "rtdl_FTTransformer     37\n",
      "SAINT                  77\n",
      "NAM                    79\n",
      "DeepFM                 90\n",
      "TabTransformer        124\n",
      "rtdl_ResNet           127\n",
      "DANet                 130\n",
      "rtdl_MLP              135\n",
      "NODE                  138\n",
      "SVM                   143\n",
      "VIME                  163\n",
      "STG                   164\n",
      "CatBoost              165\n",
      "LightGBM              165\n",
      "KNN                   167\n",
      "LinearModel           168\n",
      "TabNet                168\n",
      "RandomForest          173\n",
      "XGBoost               174\n",
      "DecisionTree          175\n",
      "MLP                   175\n",
      "Name: dataset_name, dtype: int64\n",
      "for each dataset: number of algs with results (out of 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataset_name\n",
       "openml__poker-hand__9890                                   4\n",
       "openml__Devnagari-Script__167121                           6\n",
       "openml__covertype__7593                                    7\n",
       "openml__albert__189356                                     7\n",
       "openml__helena__168329                                     8\n",
       "openml__walking-activity__9945                             8\n",
       "openml__CIFAR_10__167124                                  10\n",
       "openml__guillermo__168337                                 10\n",
       "openml__Fashion-MNIST__146825                             10\n",
       "openml__riccardo__168338                                  10\n",
       "openml__airlines__189354                                  11\n",
       "openml__skin-segmentation__9965                           11\n",
       "openml__jungle_chess_2pcs_raw_endgame_complete__167119    11\n",
       "openml__robert__168332                                    11\n",
       "openml__MiniBooNE__168335                                 12\n",
       "openml__ldpa__9974                                        12\n",
       "openml__mnist_784__3573                                   12\n",
       "openml__Census-Income__168340                             12\n",
       "openml__dilbert__168909                                   13\n",
       "openml__jannis__168330                                    13\n",
       "openml__higgs__146606                                     13\n",
       "openml__chess__3952                                       13\n",
       "openml__volkert__168331                                   13\n",
       "openml__kropt__2076                                       14\n",
       "openml__connect-4__146195                                 14\n",
       "openml__nursery__9892                                     14\n",
       "openml__pendigits__32                                     14\n",
       "openml__isolet__3481                                      14\n",
       "openml__shuttle__146212                                   14\n",
       "openml__har__14970                                        14\n",
       "openml__gas-drift-different-concentrations__9987          14\n",
       "openml__numerai28.6__167120                               14\n",
       "openml__one-hundred-plants-texture__9956                  15\n",
       "openml__soybean__41                                       15\n",
       "openml__fabert__168910                                    15\n",
       "openml__sylvine__168912                                   15\n",
       "openml__letter__6                                         15\n",
       "openml__APSFailure__168868                                15\n",
       "openml__JapaneseVowels__3510                              15\n",
       "openml__artificial-characters__14964                      15\n",
       "openml__synthetic_control__3512                           16\n",
       "openml__solar-flare__2068                                 16\n",
       "openml__first-order-theorem-proving__9985                 16\n",
       "openml__audiology__7                                      16\n",
       "openml__Internet-Advertisements__167125                   16\n",
       "openml__eeg-eye-state__14951                              16\n",
       "openml__ecoli__145977                                     16\n",
       "openml__steel-plates-fault__146817                        16\n",
       "openml__segment__146822                                   16\n",
       "openml__house_16H__3686                                   16\n",
       "openml__sylva_agnostic__3889                              16\n",
       "openml__satimage__2074                                    16\n",
       "openml__page-blocks__30                                   16\n",
       "openml__gas-drift__9986                                   16\n",
       "openml__LED-display-domain-7digit__125921                 16\n",
       "openml__hayes-roth__146063                                16\n",
       "openml__primary-tumor__146032                             16\n",
       "openml__pollen__3735                                      16\n",
       "openml__optdigits__28                                     16\n",
       "openml__car-evaluation__146192                            16\n",
       "openml__mfeat-karhunen__16                                16\n",
       "openml__mfeat-morphological__18                           16\n",
       "openml__cjs__14967                                        16\n",
       "openml__mfeat-pixel__146824                               16\n",
       "openml__mfeat-zernike__22                                 16\n",
       "openml__texture__125922                                   16\n",
       "openml__Satellite__167211                                 16\n",
       "openml__gina_agnostic__3891                               17\n",
       "openml__MiceProtein__146800                               17\n",
       "openml__GesturePhaseSegmentationProcessed__14969          17\n",
       "openml__MagicTelescope__3954                              17\n",
       "openml__wilt__146820                                      17\n",
       "openml__analcatdata_dmft__3560                            17\n",
       "openml__magic__146206                                     17\n",
       "openml__iris__59                                          17\n",
       "openml__lung-cancer__146024                               17\n",
       "openml__nomao__9977                                       17\n",
       "openml__philippine__190410                                17\n",
       "openml__yeast__145793                                     17\n",
       "openml__Amazon_employee_access__34539                     17\n",
       "openml__transplant__3748                                  17\n",
       "openml__car__146821                                       17\n",
       "openml__vehicle__53                                       17\n",
       "openml__balance-scale__11                                 17\n",
       "openml__cnae-9__9981                                      17\n",
       "openml__splice__45                                        17\n",
       "openml__dna__167140                                       17\n",
       "openml__Bioresponse__9910                                 17\n",
       "openml__christine__168908                                 17\n",
       "openml__libras__360948                                    18\n",
       "openml__lymph__10                                         18\n",
       "openml__mfeat-factors__12                                 18\n",
       "openml__mfeat-fourier__14                                 18\n",
       "openml__fri_c0_100_5__3620                                18\n",
       "openml__postoperative-patient-data__146210                18\n",
       "openml__monks-problems-2__146065                          18\n",
       "openml__phoneme__9952                                     18\n",
       "openml__musk__3950                                        18\n",
       "openml__cardiotocography__9979                            18\n",
       "openml__SpeedDating__146607                               18\n",
       "openml__PhishingWebsites__14952                           18\n",
       "openml__wall-robot-navigation__9960                       18\n",
       "openml__blood-transfusion-service-center__145836          18\n",
       "openml__visualizing_environmental__3602                   18\n",
       "openml__banknote-authentication__10093                    18\n",
       "openml__tic-tac-toe__49                                   18\n",
       "openml__qsar-biodeg__9957                                 18\n",
       "openml__Click_prediction_small__190408                    18\n",
       "openml__eye_movements__3897                               18\n",
       "openml__eucalyptus__2079                                  18\n",
       "openml__arrhythmia__5                                     18\n",
       "openml__semeion__9964                                     18\n",
       "openml__autos__9                                          18\n",
       "openml__sonar__39                                         18\n",
       "openml__anneal__2867                                      18\n",
       "openml__glass__40                                         18\n",
       "openml__tae__47                                           18\n",
       "openml__analcatdata_chlamydia__3739                       18\n",
       "openml__analcatdata_boxing1__3540                         18\n",
       "openml__jm1__3904                                         18\n",
       "openml__analcatdata_authorship__3549                      18\n",
       "openml__kc1__3917                                         18\n",
       "openml__kc2__3913                                         18\n",
       "openml__rabe_266__3647                                    18\n",
       "openml__dermatology__35                                   18\n",
       "openml__fl2000__3566                                      18\n",
       "openml__wdbc__9946                                        19\n",
       "openml__scene__3485                                       19\n",
       "openml__vowel__3022                                       19\n",
       "openml__visualizing_livestock__3731                       19\n",
       "openml__spambase__43                                      19\n",
       "openml__pc4__3902                                         19\n",
       "openml__blood-transfusion-service-center__10101           19\n",
       "openml__pc1__3918                                         19\n",
       "openml__breast-cancer__145799                             19\n",
       "openml__breast-w__15                                      19\n",
       "openml__bank-marketing__9899                              19\n",
       "openml__climate-model-simulation-crashes__146819          19\n",
       "openml__cmc__23                                           19\n",
       "openml__colic__27                                         19\n",
       "openml__collins__3567                                     19\n",
       "openml__elevators__3711                                   19\n",
       "openml__fertility__9984                                   19\n",
       "openml__pc3__3903                                         19\n",
       "openml__ionosphere__145984                                19\n",
       "openml__fri_c3_100_5__3779                                19\n",
       "openml__mushroom__24                                      19\n",
       "openml__ada_agnostic__3896                                19\n",
       "openml__kr-vs-kp__3                                       19\n",
       "openml__adult__7592                                       19\n",
       "openml__cylinder-bands__14954                             20\n",
       "openml__ozone-level-8hr__9978                             20\n",
       "openml__acute-inflammations__10089                        20\n",
       "openml__churn__167141                                     20\n",
       "openml__Australian__146818                                20\n",
       "openml__madelon__9976                                     20\n",
       "openml__colic__25                                         20\n",
       "openml__labor__4                                          20\n",
       "openml__profb__3561                                       20\n",
       "openml__bank-marketing__14965                             20\n",
       "openml__credit-approval__29                               20\n",
       "openml__adult-census__3953                                20\n",
       "openml__diabetes__37                                      20\n",
       "openml__electricity__219                                  20\n",
       "openml__haberman__42                                      20\n",
       "openml__sick__3021                                        20\n",
       "openml__heart-h__50                                       20\n",
       "openml__hepatitis__54                                     20\n",
       "openml__hill-valley__145847                               20\n",
       "openml__credit-g__31                                      20\n",
       "openml__irish__3543                                       21\n",
       "openml__dresses-sales__125920                             21\n",
       "openml__jasmine__168911                                   21\n",
       "openml__socmob__3797                                      21\n",
       "openml__heart-c__48                                       21\n",
       "openml__ilpd__9971                                        21\n",
       "Name: alg_name, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each alg, for how many datasets are there results?\n",
    "print(f\"for each alg: number of datasets with results (out of {len(metadataset_df['dataset_name'].unique())})\")\n",
    "print(metadataset_df.groupby(\"alg_name\")[\"dataset_name\"].apply(lambda x: len(set(x))).sort_values())\n",
    "\n",
    "print(f\"for each dataset: number of algs with results (out of {len(metadataset_df['alg_name'].unique())})\")\n",
    "metadataset_df.groupby(\"dataset_name\")[\"alg_name\"].apply(lambda x: len(set(x))).sort_values()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove datasets with few results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each dataset: number of algs with results\n",
      "dataset_name\n",
      "openml__poker-hand__9890                                   4\n",
      "openml__Devnagari-Script__167121                           6\n",
      "openml__covertype__7593                                    7\n",
      "openml__albert__189356                                     7\n",
      "openml__helena__168329                                     8\n",
      "openml__walking-activity__9945                             8\n",
      "openml__CIFAR_10__167124                                  10\n",
      "openml__guillermo__168337                                 10\n",
      "openml__Fashion-MNIST__146825                             10\n",
      "openml__riccardo__168338                                  10\n",
      "openml__airlines__189354                                  11\n",
      "openml__skin-segmentation__9965                           11\n",
      "openml__jungle_chess_2pcs_raw_endgame_complete__167119    11\n",
      "openml__robert__168332                                    11\n",
      "openml__MiniBooNE__168335                                 12\n",
      "openml__ldpa__9974                                        12\n",
      "openml__mnist_784__3573                                   12\n",
      "openml__Census-Income__168340                             12\n",
      "openml__dilbert__168909                                   13\n",
      "openml__jannis__168330                                    13\n",
      "openml__higgs__146606                                     13\n",
      "openml__chess__3952                                       13\n",
      "openml__volkert__168331                                   13\n",
      "openml__kropt__2076                                       14\n",
      "openml__connect-4__146195                                 14\n",
      "openml__nursery__9892                                     14\n",
      "openml__pendigits__32                                     14\n",
      "openml__isolet__3481                                      14\n",
      "openml__shuttle__146212                                   14\n",
      "openml__har__14970                                        14\n",
      "openml__gas-drift-different-concentrations__9987          14\n",
      "openml__numerai28.6__167120                               14\n",
      "openml__one-hundred-plants-texture__9956                  15\n",
      "openml__soybean__41                                       15\n",
      "openml__fabert__168910                                    15\n",
      "openml__sylvine__168912                                   15\n",
      "openml__letter__6                                         15\n",
      "openml__APSFailure__168868                                15\n",
      "openml__JapaneseVowels__3510                              15\n",
      "openml__artificial-characters__14964                      15\n",
      "openml__synthetic_control__3512                           16\n",
      "openml__solar-flare__2068                                 16\n",
      "openml__first-order-theorem-proving__9985                 16\n",
      "openml__audiology__7                                      16\n",
      "openml__Internet-Advertisements__167125                   16\n",
      "openml__eeg-eye-state__14951                              16\n",
      "openml__ecoli__145977                                     16\n",
      "openml__steel-plates-fault__146817                        16\n",
      "openml__segment__146822                                   16\n",
      "openml__house_16H__3686                                   16\n",
      "openml__sylva_agnostic__3889                              16\n",
      "openml__satimage__2074                                    16\n",
      "openml__page-blocks__30                                   16\n",
      "openml__gas-drift__9986                                   16\n",
      "openml__LED-display-domain-7digit__125921                 16\n",
      "openml__hayes-roth__146063                                16\n",
      "openml__primary-tumor__146032                             16\n",
      "openml__pollen__3735                                      16\n",
      "openml__optdigits__28                                     16\n",
      "openml__car-evaluation__146192                            16\n",
      "openml__mfeat-karhunen__16                                16\n",
      "openml__mfeat-morphological__18                           16\n",
      "openml__cjs__14967                                        16\n",
      "openml__mfeat-pixel__146824                               16\n",
      "openml__mfeat-zernike__22                                 16\n",
      "openml__texture__125922                                   16\n",
      "openml__Satellite__167211                                 16\n",
      "openml__gina_agnostic__3891                               17\n",
      "openml__MiceProtein__146800                               17\n",
      "openml__GesturePhaseSegmentationProcessed__14969          17\n",
      "openml__MagicTelescope__3954                              17\n",
      "openml__wilt__146820                                      17\n",
      "openml__analcatdata_dmft__3560                            17\n",
      "openml__magic__146206                                     17\n",
      "openml__iris__59                                          17\n",
      "openml__lung-cancer__146024                               17\n",
      "openml__nomao__9977                                       17\n",
      "openml__philippine__190410                                17\n",
      "openml__yeast__145793                                     17\n",
      "openml__Amazon_employee_access__34539                     17\n",
      "openml__transplant__3748                                  17\n",
      "openml__car__146821                                       17\n",
      "openml__vehicle__53                                       17\n",
      "openml__balance-scale__11                                 17\n",
      "openml__cnae-9__9981                                      17\n",
      "openml__splice__45                                        17\n",
      "openml__dna__167140                                       17\n",
      "openml__Bioresponse__9910                                 17\n",
      "openml__christine__168908                                 17\n",
      "openml__libras__360948                                    18\n",
      "openml__lymph__10                                         18\n",
      "openml__mfeat-factors__12                                 18\n",
      "openml__mfeat-fourier__14                                 18\n",
      "openml__fri_c0_100_5__3620                                18\n",
      "openml__postoperative-patient-data__146210                18\n",
      "openml__monks-problems-2__146065                          18\n",
      "openml__phoneme__9952                                     18\n",
      "openml__musk__3950                                        18\n",
      "openml__cardiotocography__9979                            18\n",
      "openml__SpeedDating__146607                               18\n",
      "openml__PhishingWebsites__14952                           18\n",
      "openml__wall-robot-navigation__9960                       18\n",
      "openml__blood-transfusion-service-center__145836          18\n",
      "openml__visualizing_environmental__3602                   18\n",
      "openml__banknote-authentication__10093                    18\n",
      "openml__tic-tac-toe__49                                   18\n",
      "openml__qsar-biodeg__9957                                 18\n",
      "openml__Click_prediction_small__190408                    18\n",
      "openml__eye_movements__3897                               18\n",
      "openml__eucalyptus__2079                                  18\n",
      "openml__arrhythmia__5                                     18\n",
      "openml__semeion__9964                                     18\n",
      "openml__autos__9                                          18\n",
      "openml__sonar__39                                         18\n",
      "openml__anneal__2867                                      18\n",
      "openml__glass__40                                         18\n",
      "openml__tae__47                                           18\n",
      "openml__analcatdata_chlamydia__3739                       18\n",
      "openml__analcatdata_boxing1__3540                         18\n",
      "openml__jm1__3904                                         18\n",
      "openml__analcatdata_authorship__3549                      18\n",
      "openml__kc1__3917                                         18\n",
      "openml__kc2__3913                                         18\n",
      "openml__rabe_266__3647                                    18\n",
      "openml__dermatology__35                                   18\n",
      "openml__fl2000__3566                                      18\n",
      "openml__wdbc__9946                                        19\n",
      "openml__scene__3485                                       19\n",
      "openml__vowel__3022                                       19\n",
      "openml__visualizing_livestock__3731                       19\n",
      "openml__spambase__43                                      19\n",
      "openml__pc4__3902                                         19\n",
      "openml__blood-transfusion-service-center__10101           19\n",
      "openml__pc1__3918                                         19\n",
      "openml__breast-cancer__145799                             19\n",
      "openml__breast-w__15                                      19\n",
      "openml__bank-marketing__9899                              19\n",
      "openml__climate-model-simulation-crashes__146819          19\n",
      "openml__cmc__23                                           19\n",
      "openml__colic__27                                         19\n",
      "openml__collins__3567                                     19\n",
      "openml__elevators__3711                                   19\n",
      "openml__fertility__9984                                   19\n",
      "openml__pc3__3903                                         19\n",
      "openml__ionosphere__145984                                19\n",
      "openml__fri_c3_100_5__3779                                19\n",
      "openml__mushroom__24                                      19\n",
      "openml__ada_agnostic__3896                                19\n",
      "openml__kr-vs-kp__3                                       19\n",
      "openml__adult__7592                                       19\n",
      "openml__cylinder-bands__14954                             20\n",
      "openml__ozone-level-8hr__9978                             20\n",
      "openml__acute-inflammations__10089                        20\n",
      "openml__churn__167141                                     20\n",
      "openml__Australian__146818                                20\n",
      "openml__madelon__9976                                     20\n",
      "openml__colic__25                                         20\n",
      "openml__labor__4                                          20\n",
      "openml__profb__3561                                       20\n",
      "openml__bank-marketing__14965                             20\n",
      "openml__credit-approval__29                               20\n",
      "openml__adult-census__3953                                20\n",
      "openml__diabetes__37                                      20\n",
      "openml__electricity__219                                  20\n",
      "openml__haberman__42                                      20\n",
      "openml__sick__3021                                        20\n",
      "openml__heart-h__50                                       20\n",
      "openml__hepatitis__54                                     20\n",
      "openml__hill-valley__145847                               20\n",
      "openml__credit-g__31                                      20\n",
      "openml__irish__3543                                       21\n",
      "openml__dresses-sales__125920                             21\n",
      "openml__jasmine__168911                                   21\n",
      "openml__socmob__3797                                      21\n",
      "openml__heart-c__48                                       21\n",
      "openml__ilpd__9971                                        21\n",
      "Name: alg_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"for each dataset: number of algs with results\")\n",
    "alg_counts = metadataset_df.groupby(\"dataset_name\")[\"alg_name\"].agg(lambda x: len(set(x))).sort_values()\n",
    "print(alg_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 6 datasets:\n",
      "dataset_name\n",
      "openml__poker-hand__9890            4\n",
      "openml__Devnagari-Script__167121    6\n",
      "openml__covertype__7593             7\n",
      "openml__albert__189356              7\n",
      "openml__helena__168329              8\n",
      "openml__walking-activity__9945      8\n",
      "Name: alg_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "keep_datasets = list(alg_counts[alg_counts >= 10].index)\n",
    "drop_datasets = alg_counts[alg_counts < 10]\n",
    "\n",
    "print(f\"dropping {len(drop_datasets)} datasets:\")\n",
    "print(drop_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each alg: number of datasets with results\n",
      "alg_name\n",
      "rtdl_FTTransformer     37\n",
      "SAINT                  77\n",
      "NAM                    79\n",
      "DeepFM                 90\n",
      "TabTransformer        124\n",
      "rtdl_ResNet           127\n",
      "DANet                 130\n",
      "rtdl_MLP              135\n",
      "NODE                  138\n",
      "SVM                   143\n",
      "VIME                  163\n",
      "STG                   164\n",
      "CatBoost              165\n",
      "LightGBM              165\n",
      "KNN                   167\n",
      "LinearModel           168\n",
      "TabNet                168\n",
      "RandomForest          173\n",
      "XGBoost               174\n",
      "DecisionTree          175\n",
      "MLP                   175\n",
      "Name: dataset_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"for each alg: number of datasets with results\")\n",
    "dataset_counts = metadataset_df.groupby(\"alg_name\")[\"dataset_name\"].agg(lambda x: len(set(x))).sort_values()\n",
    "print(dataset_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep all algs, regardless of how many datasets they have results for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after removing datasets: number of datasets with results\n",
      "alg_name\n",
      "rtdl_FTTransformer     37\n",
      "SAINT                  77\n",
      "NAM                    79\n",
      "DeepFM                 90\n",
      "TabTransformer        122\n",
      "rtdl_ResNet           125\n",
      "DANet                 130\n",
      "rtdl_MLP              133\n",
      "NODE                  138\n",
      "SVM                   143\n",
      "VIME                  162\n",
      "CatBoost              162\n",
      "STG                   163\n",
      "LightGBM              163\n",
      "KNN                   163\n",
      "LinearModel           166\n",
      "TabNet                166\n",
      "MLP                   169\n",
      "RandomForest          169\n",
      "XGBoost               170\n",
      "DecisionTree          170\n",
      "Name: dataset_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "metadataset_df = metadataset_df.loc[metadataset_df[\"dataset_name\"].isin(keep_datasets), :]\n",
    "\n",
    "print(\"after removing datasets: number of datasets with results\")\n",
    "dataset_counts = metadataset_df.groupby(\"alg_name\")[\"dataset_name\"].agg(lambda x: len(set(x))).sort_values()\n",
    "print(dataset_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get tuned algorithms for a given metric\n",
    "\n",
    "Report the average & median test performance, over all folds. Note that each alg is tuned for each fold separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [\n",
    "    \"Accuracy\",\n",
    "    \"F1\",\n",
    "    \"Log Loss\",\n",
    "]\n",
    "\n",
    "obj_type_list = [\n",
    "    \"maximize\",\n",
    "    \"maximize\",\n",
    "    \"minimize\",\n",
    "]\n",
    "result_df_dict = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a copy of each \"default\" hparam row, to treat this as a separate alg\n",
    "default_rows = metadataset_df.loc[metadataset_df[\"hparam_source\"] == \"default\"].copy()\n",
    "default_rows.loc[:, \"alg_name\"] = default_rows[\"alg_name\"].apply(lambda x: x + \"_default\")\n",
    "\n",
    "# append these to the metadataset\n",
    "metadataset_df = pd.concat([metadataset_df, default_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_result_dfs = {}\n",
    "for drop_default in [True, False]:\n",
    "    for i, (metric, objective_type) in enumerate(zip(metric_list, obj_type_list)):\n",
    "\n",
    "        test_metric_col = metric + \"__test\"\n",
    "\n",
    "        if drop_default:\n",
    "            df = metadataset_df.loc[~metadataset_df[\"alg_name\"].str.contains(\"_default\"), :].copy()\n",
    "        else:\n",
    "            df = metadataset_df.copy()\n",
    "\n",
    "        tuned_alg_perf = get_tuned_alg_perf(df, metric=metric)\n",
    "        # NOTE: this \"tunes\" each algorithm for each training fold separately. so each of the 10 folds might use different hparams.\n",
    "        tuned_result_dfs[metric] = tuned_alg_perf\n",
    "\n",
    "        ##############################\n",
    "        ### STEP 1: TREAT EACH FOLD AS SEPARATE DATASET\n",
    "\n",
    "        # result_col = test_metric_col\n",
    "        \n",
    "        # # for each dataset, find the min and max metrics over all tuned algs\n",
    "        # overall_bounds = tuned_alg_perf.groupby(\"dataset_fold_id\").agg({result_col: [\"min\", \"max\"]}).reset_index()\n",
    "\n",
    "        # # rename the multiindex cols\n",
    "        # new_cols = []\n",
    "        # for c in overall_bounds.columns:\n",
    "        #     if c[1] == \"\":\n",
    "        #         new_cols.append(c[0])\n",
    "        #     else:\n",
    "        #         new_cols.append(\"_\".join(c))\n",
    "\n",
    "        # overall_bounds.columns = new_cols\n",
    "\n",
    "        # tuned_alg_perf = tuned_alg_perf.merge(overall_bounds, on=\"dataset_fold_id\", how=\"left\")\n",
    "\n",
    "        # # add normalized metric\n",
    "        # tuned_alg_perf.loc[:, \"normalized_\" + result_col] = (tuned_alg_perf[result_col] - tuned_alg_perf[result_col + \"_min\"]) / (tuned_alg_perf[result_col + \"_max\"] - tuned_alg_perf[result_col + \"_min\"])\n",
    "\n",
    "        # # rank all algs for each dataset\n",
    "        # ascending = False if objective_type == \"maximize\" else True\n",
    "        \n",
    "        # tuned_alg_perf.loc[:, f\"{metric}_rank\"] = tuned_alg_perf.groupby([\"dataset_fold_id\"])[result_col].rank(method=\"min\", ascending=ascending).values\n",
    "\n",
    "        # if i == 0:\n",
    "        #     fold_tuned_df = tuned_alg_perf.copy()\n",
    "        # else:\n",
    "        #     fold_tuned_df = fold_tuned_df.merge(tuned_alg_perf, on=[\"alg_name\", \"dataset_fold_id\"])\n",
    "\n",
    "        # fold_result_df_dict[metric] = tuned_alg_perf.copy()\n",
    "\n",
    "        ##############################\n",
    "        ### STEP 2: AVERAGE OVER FOLDS\n",
    "\n",
    "        if i == 0:\n",
    "            agg_dict = {\n",
    "                test_metric_col: [\"median\", \"mean\"],\n",
    "                \"time__train\": [\"median\", \"mean\"],\n",
    "                \"dataset_name\": [\"count\"],\n",
    "            }\n",
    "        else:\n",
    "            agg_dict = {\n",
    "                test_metric_col: [\"median\", \"mean\"],\n",
    "            }\n",
    "\n",
    "        # aggregate over folds: take the mean & median performance over each fold\n",
    "        agg_tuned_alg_perf = tuned_alg_perf.groupby([\"alg_name\", \"dataset_name\"]).agg(agg_dict).reset_index()\n",
    "\n",
    "        # rename the multiindex cols\n",
    "        new_cols = []\n",
    "        for c in agg_tuned_alg_perf.columns:\n",
    "            if c[1] == \"\":\n",
    "                new_cols.append(c[0])\n",
    "            else:\n",
    "                new_cols.append(\"_\".join(c))\n",
    "\n",
    "        agg_tuned_alg_perf.columns = new_cols\n",
    "\n",
    "\n",
    "        # define the target metric column, we will use this value for all plots\n",
    "        result_col = test_metric_col + \"_mean\"\n",
    "\n",
    "        # for each dataset, find the min and max metrics over all tuned algs\n",
    "        overall_bounds = agg_tuned_alg_perf.groupby(\"dataset_name\").agg({result_col: [\"min\", \"max\"]}).reset_index()\n",
    "\n",
    "        # adjust the lower bound to be the metric for a tuned decision tree (this is the \"baseline\")\n",
    "        # baseline_metric = agg_tuned_alg_perf.loc[agg_tuned_alg_perf[\"alg_name\"] == \"DecisionTree\"].groupby(\"dataset_name\").agg({result_col: \"max\"}).reset_index()\n",
    "\n",
    "        # baseline_metric.columns = [\"dataset_name\", \"baseline_metric\"]\n",
    "        \n",
    "        # rename the multiindex cols\n",
    "        new_cols = []\n",
    "        for c in overall_bounds.columns:\n",
    "            if c[1] == \"\":\n",
    "                new_cols.append(c[0])\n",
    "            else:\n",
    "                new_cols.append(\"_\".join(c))\n",
    "\n",
    "        overall_bounds.columns = new_cols\n",
    "\n",
    "        \n",
    "        agg_tuned_alg_perf = agg_tuned_alg_perf.merge(overall_bounds, on=\"dataset_name\", how=\"left\") #. \\\n",
    "            # merge(baseline_metric, on=\"dataset_name\", how=\"left\")\n",
    "\n",
    "        # add normalized metric\n",
    "        agg_tuned_alg_perf.loc[:, \"normalized_\" + result_col] = (agg_tuned_alg_perf[result_col] - agg_tuned_alg_perf[result_col + \"_min\"]) / (agg_tuned_alg_perf[result_col + \"_max\"] - agg_tuned_alg_perf[result_col + \"_min\"])\n",
    "\n",
    "        # rank all algs for each dataset\n",
    "        ascending = False if objective_type == \"maximize\" else True\n",
    "        \n",
    "        # rank according to mean or median performance over all folds\n",
    "        for agg_method in [\"mean\", \"median\"]:\n",
    "            agg_tuned_alg_perf.loc[:, f\"{metric}_rank\" + \"_\" + agg_method] = agg_tuned_alg_perf.groupby([\"dataset_name\"])[test_metric_col + \"_\" + agg_method].rank(method=\"min\", ascending=ascending).values\n",
    "\n",
    "        if i == 0:\n",
    "            tuned_agg_df = agg_tuned_alg_perf.copy()\n",
    "        else:\n",
    "            tuned_agg_df = tuned_agg_df.merge(agg_tuned_alg_perf, on=[\"alg_name\", \"dataset_name\"])\n",
    "\n",
    "        # result_df_dict[metric] = agg_tuned_alg_perf.copy()\n",
    "\n",
    "        if drop_default:\n",
    "            tuned_agg_df_no_default = tuned_agg_df.copy()\n",
    "            tuned_agg_df.to_csv(\"./results/tuned_aggregated_results.csv\")\n",
    "        else:\n",
    "            tuned_agg_df_with_default = tuned_agg_df.copy()\n",
    "            tuned_agg_df.to_csv(\"./results/tuned_aggregated_results_with_default_hparams.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>Accuracy__test_median</th>\n",
       "      <th>Accuracy__test_mean</th>\n",
       "      <th>time__train_median</th>\n",
       "      <th>time__train_mean</th>\n",
       "      <th>dataset_name_count</th>\n",
       "      <th>Accuracy__test_mean_min</th>\n",
       "      <th>Accuracy__test_mean_max</th>\n",
       "      <th>normalized_Accuracy__test_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_F1__test_mean</th>\n",
       "      <th>F1_rank_mean</th>\n",
       "      <th>F1_rank_median</th>\n",
       "      <th>Log Loss__test_median</th>\n",
       "      <th>Log Loss__test_mean</th>\n",
       "      <th>Log Loss__test_mean_min</th>\n",
       "      <th>Log Loss__test_mean_max</th>\n",
       "      <th>normalized_Log Loss__test_mean</th>\n",
       "      <th>Log Loss_rank_mean</th>\n",
       "      <th>Log Loss_rank_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>openml__Bioresponse__9910</td>\n",
       "      <td>0.798940</td>\n",
       "      <td>0.795521</td>\n",
       "      <td>5.815126</td>\n",
       "      <td>6.748842</td>\n",
       "      <td>10</td>\n",
       "      <td>0.727272</td>\n",
       "      <td>0.796848</td>\n",
       "      <td>0.980938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980938</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.455072</td>\n",
       "      <td>0.456102</td>\n",
       "      <td>0.451718</td>\n",
       "      <td>0.967133</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>CatBoost_default</td>\n",
       "      <td>openml__Bioresponse__9910</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.782994</td>\n",
       "      <td>2.447543</td>\n",
       "      <td>2.595033</td>\n",
       "      <td>10</td>\n",
       "      <td>0.727272</td>\n",
       "      <td>0.796848</td>\n",
       "      <td>0.800881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800881</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.474727</td>\n",
       "      <td>0.477421</td>\n",
       "      <td>0.451718</td>\n",
       "      <td>0.967133</td>\n",
       "      <td>0.049868</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             alg_name               dataset_name  Accuracy__test_median  \\\n",
       "3            CatBoost  openml__Bioresponse__9910               0.798940   \n",
       "165  CatBoost_default  openml__Bioresponse__9910               0.786667   \n",
       "\n",
       "     Accuracy__test_mean  time__train_median  time__train_mean  \\\n",
       "3               0.795521            5.815126          6.748842   \n",
       "165             0.782994            2.447543          2.595033   \n",
       "\n",
       "     dataset_name_count  Accuracy__test_mean_min  Accuracy__test_mean_max  \\\n",
       "3                    10                 0.727272                 0.796848   \n",
       "165                  10                 0.727272                 0.796848   \n",
       "\n",
       "     normalized_Accuracy__test_mean  ...  normalized_F1__test_mean  \\\n",
       "3                          0.980938  ...                  0.980938   \n",
       "165                        0.800881  ...                  0.800881   \n",
       "\n",
       "     F1_rank_mean  F1_rank_median  Log Loss__test_median  Log Loss__test_mean  \\\n",
       "3             2.0             2.0               0.455072             0.456102   \n",
       "165           8.0             6.0               0.474727             0.477421   \n",
       "\n",
       "     Log Loss__test_mean_min  Log Loss__test_mean_max  \\\n",
       "3                   0.451718                 0.967133   \n",
       "165                 0.451718                 0.967133   \n",
       "\n",
       "     normalized_Log Loss__test_mean  Log Loss_rank_mean  Log Loss_rank_median  \n",
       "3                          0.008506                 4.0                   1.0  \n",
       "165                        0.049868                 6.0                   7.0  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check..\n",
    "# result_df_dict[\"Accuracy\"][result_df_dict[\"Accuracy\"][\"dataset_name\"] == \"openml__Amazon_employee_access__34539\"]\n",
    "# tuned_agg_df_with_default[(tuned_agg_df_with_default[\"dataset_name\"] == \"openml__Amazon_employee_access__34539\") & tuned_agg_df_with_default[\"alg_name\"].str.contains(\"CatBoost\")]\n",
    "\n",
    "tuned_agg_df_with_default[(tuned_agg_df_with_default[\"dataset_name\"] == \"openml__Bioresponse__9910\") & tuned_agg_df_with_default[\"alg_name\"].str.contains(\"CatBoost\")]\n",
    "\n",
    "# fold_tuned_df[fold_tuned_df[\"dataset_fold_id\"] == \"openml__APSFailure__168868__fold_1\"]\n",
    "# fold_tuned_df[fold_tuned_df[\"dataset_fold_id\"] == \"openml__Amazon_employee_access__34539__fold_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write tuned df to file\n",
    "# tuned_agg_df.to_csv(\"./results/tuned_aggregated_results.csv\")\n",
    "# fold_tuned_df.to_csv(\"./results/tuned_fold_results.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between best neural and best non-neural method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now tune by algorithm type. first define the type as \"neural\" or \"non-neural\"\n",
    "neural_algs = [\n",
    "    \"MLP\",\n",
    "    \"TabNet\",\n",
    "    \"VIME\",\n",
    "    \"TabTransformer\",\n",
    "    \"NODE\",\n",
    "    \"STG\",\n",
    "    \"NAM\",\n",
    "    \"DeepFM\",\n",
    "    \"SAINT\",\n",
    "    \"DANet\",\n",
    "    \"rtdl_MLP\",\n",
    "    \"rtdl_ResNet\",\n",
    "    \"rtdl_FTTransformer\",\n",
    "]\n",
    "\n",
    "metadataset_df.loc[:, \"alg_type\"] = \"non-neural\"\n",
    "metadataset_df.loc[metadataset_df[\"alg_name\"].isin(neural_algs), \"alg_type\"] = \"neural\"\n",
    "\n",
    "tuned_df = get_tuned_alg_perf(metadataset_df, metric=metric, group_col=\"alg_type\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Accuracy__test             F1__test  \\\n",
      "alg_type                                   neural non-neural    neural   \n",
      "dataset_fold_id                                                          \n",
      "openml__APSFailure__168868__fold_0       0.992763   0.995263  0.992763   \n",
      "openml__APSFailure__168868__fold_1       0.988684   0.992237  0.988684   \n",
      "openml__APSFailure__168868__fold_2       0.990395   0.993947  0.990395   \n",
      "openml__APSFailure__168868__fold_3       0.992368   0.995526  0.992368   \n",
      "openml__APSFailure__168868__fold_4       0.991184   0.995789  0.991184   \n",
      "\n",
      "                                              MSE__test             \\\n",
      "alg_type                           non-neural    neural non-neural   \n",
      "dataset_fold_id                                                      \n",
      "openml__APSFailure__168868__fold_0   0.995263       NaN        NaN   \n",
      "openml__APSFailure__168868__fold_1   0.992237       NaN        NaN   \n",
      "openml__APSFailure__168868__fold_2   0.993947       NaN        NaN   \n",
      "openml__APSFailure__168868__fold_3   0.995526       NaN        NaN   \n",
      "openml__APSFailure__168868__fold_4   0.995789       NaN        NaN   \n",
      "\n",
      "                                   Log Loss__test                   alg_name  \\\n",
      "alg_type                                   neural non-neural          neural   \n",
      "dataset_fold_id                                                                \n",
      "openml__APSFailure__168868__fold_0       0.019384    0.01648  TabTransformer   \n",
      "openml__APSFailure__168868__fold_1       0.030806   0.022713  TabTransformer   \n",
      "openml__APSFailure__168868__fold_2       0.026238   0.020097  TabTransformer   \n",
      "openml__APSFailure__168868__fold_3       0.024933   0.018053  TabTransformer   \n",
      "openml__APSFailure__168868__fold_4       0.030389   0.013555  TabTransformer   \n",
      "\n",
      "                                              time__train             \\\n",
      "alg_type                           non-neural      neural non-neural   \n",
      "dataset_fold_id                                                        \n",
      "openml__APSFailure__168868__fold_0   LightGBM  156.269556  25.718933   \n",
      "openml__APSFailure__168868__fold_1    XGBoost  336.442136   0.940423   \n",
      "openml__APSFailure__168868__fold_2    XGBoost  380.952997    1.18313   \n",
      "openml__APSFailure__168868__fold_3    XGBoost  381.007164   1.730255   \n",
      "openml__APSFailure__168868__fold_4    XGBoost  178.289103   2.699572   \n",
      "\n",
      "                                   time__test             \n",
      "alg_type                               neural non-neural  \n",
      "dataset_fold_id                                           \n",
      "openml__APSFailure__168868__fold_0   0.123314   0.100582  \n",
      "openml__APSFailure__168868__fold_1   0.112383   0.056885  \n",
      "openml__APSFailure__168868__fold_2   0.117252   0.066141  \n",
      "openml__APSFailure__168868__fold_3   0.118603   0.082695  \n",
      "openml__APSFailure__168868__fold_4   0.142411   0.085889  \n"
     ]
    }
   ],
   "source": [
    "# for each dataset fold, get difference between tuned neural and non-neural method (neural - non-neural)\n",
    "neural_non_neural_comparison = pd.pivot(tuned_df, index=\"dataset_fold_id\", columns=[\"alg_type\"], values=[\"Accuracy__test\", \"F1__test\", \"MSE__test\", \"Log Loss__test\", \"alg_name\", \"time__train\", \"time__test\"])\n",
    "print(neural_non_neural_comparison.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the differences between neural and non-neural algs\n",
    "\n",
    "# first rename the multiindex cols\n",
    "new_cols = []\n",
    "for c in neural_non_neural_comparison.columns:\n",
    "    if c[1] == \"\":\n",
    "        new_cols.append(c[0])\n",
    "    else:\n",
    "        new_cols.append(\"_\".join(c))\n",
    "\n",
    "neural_non_neural_comparison.columns = new_cols \n",
    "neural_non_neural_comparison.to_csv(\"./results/neural_non_neural_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### STEP 1: treat all folds as separate datasets\n",
    "\n",
    "# # best, worst, and average performance for each alg, over all datasets\n",
    "# for metric in metric_list:\n",
    "\n",
    "#     overall_ranks = fold_tuned_df.groupby(\"alg_name\").agg(\n",
    "#         {\n",
    "#             f\"{metric}_rank\": [\"min\", \"max\", \"mean\", \"count\"],\n",
    "#             f\"normalized_{metric}__test\": \"mean\",\n",
    "#         }\n",
    "#     ).reset_index().sort_values([(f\"{metric}_rank\", \"mean\")])\n",
    "\n",
    "#     # format min/max rank columns to be ints\n",
    "\n",
    "#     overall_ranks.loc[:, \"alg_name\"] = overall_ranks.loc[:, \"alg_name\"].apply(lambda x: \"\\rot{\" + x + \"}\")\n",
    "#     overall_ranks.loc[:, (f\"{metric}_rank\", \"min\")] = overall_ranks.loc[:, (f\"{metric}_rank\", \"min\")].astype(int).astype(str)\n",
    "#     overall_ranks.loc[:, (f\"{metric}_rank\", \"max\")] = overall_ranks.loc[:, (f\"{metric}_rank\", \"max\")].astype(int).astype(str)\n",
    "#     overall_ranks.loc[:, (f\"{metric}_rank\", \"count\")] = overall_ranks.loc[:, (f\"{metric}_rank\", \"count\")].astype(int).astype(str)\n",
    "\n",
    "#     overall_ranks.loc[:, (f\"{metric}_rank\", \"mean\")] = overall_ranks.loc[:, (f\"{metric}_rank\", \"mean\")].round(2).astype(str)\n",
    "    \n",
    "#     overall_ranks.loc[:, (f\"normalized_{metric}__test\", \"mean\")] = overall_ranks.loc[:,(f\"normalized_{metric}__test\", \"mean\")].round(2)\n",
    "\n",
    "#     print(f\"metric: {metric}\")\n",
    "#     final_table = overall_ranks.set_index(\"alg_name\").transpose()\n",
    "#     print(final_table)\n",
    "\n",
    "#     # save to csv\n",
    "#     final_table.to_csv(f\"./results/fold_rank_tables_{metric}.csv\", index=True)\n",
    "\n",
    "#     # save to latex\n",
    "#     final_table.to_latex(f\"./results/fold_rank_tables_{metric}.tex\", index=True, escape=False)\n",
    "\n",
    "\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: Accuracy\n",
      "                   Accuracy_rank_mean             \\\n",
      "                                  min max   mean   \n",
      "alg_name                                           \n",
      "CatBoost                            1  17   4.73   \n",
      "XGBoost                             1  18   5.19   \n",
      "rtdl_FTTransformer                  1  14   6.08   \n",
      "rtdl_ResNet                         1  19   6.34   \n",
      "LightGBM                            1  19   6.43   \n",
      "NODE                                1  18   6.93   \n",
      "SAINT                               1  18   7.16   \n",
      "RandomForest                        1  18   7.38   \n",
      "SVM                                 1  18   7.71   \n",
      "DANet                               1  20   7.93   \n",
      "rtdl_MLP                            1  18   8.95   \n",
      "DeepFM                              1  20   9.76   \n",
      "TabNet                              1  21  10.21   \n",
      "MLP                                 1  19  10.47   \n",
      "STG                                 1  21  10.52   \n",
      "DecisionTree                        1  20  10.52   \n",
      "TabTransformer                      1  19  10.56   \n",
      "LinearModel                         1  20  11.20   \n",
      "KNN                                 1  21  11.93   \n",
      "VIME                                1  20  13.32   \n",
      "NAM                                 1  21  14.51   \n",
      "\n",
      "                   normalized_Accuracy__test_mean count  \n",
      "                                             mean        \n",
      "alg_name                                                 \n",
      "CatBoost                                     0.88   162  \n",
      "XGBoost                                      0.88   170  \n",
      "rtdl_FTTransformer                           0.76    37  \n",
      "rtdl_ResNet                                  0.80   125  \n",
      "LightGBM                                     0.83   163  \n",
      "NODE                                         0.76   138  \n",
      "SAINT                                        0.76    77  \n",
      "RandomForest                                 0.78   169  \n",
      "SVM                                          0.75   143  \n",
      "DANet                                        0.77   130  \n",
      "rtdl_MLP                                     0.66   133  \n",
      "DeepFM                                       0.63    90  \n",
      "TabNet                                       0.64   166  \n",
      "MLP                                          0.62   169  \n",
      "STG                                          0.60   163  \n",
      "DecisionTree                                 0.60   170  \n",
      "TabTransformer                               0.57   122  \n",
      "LinearModel                                  0.52   166  \n",
      "KNN                                          0.53   163  \n",
      "VIME                                         0.41   162  \n",
      "NAM                                          0.35    79  \n",
      "\n",
      "\n",
      "metric: F1\n",
      "                   F1_rank_mean            normalized_F1__test_mean count\n",
      "                            min max   mean                     mean      \n",
      "alg_name                                                                 \n",
      "CatBoost                      1  17   4.91                     0.88   162\n",
      "XGBoost                       1  18   5.12                     0.88   170\n",
      "rtdl_ResNet                   1  19   6.38                     0.81   125\n",
      "rtdl_FTTransformer            1  15   6.46                     0.76    37\n",
      "LightGBM                      1  19   6.48                     0.84   163\n",
      "NODE                          1  18   7.07                     0.76   138\n",
      "SAINT                         1  18   7.31                     0.76    77\n",
      "RandomForest                  1  18   7.41                     0.78   169\n",
      "SVM                           1  18   7.75                     0.75   143\n",
      "DANet                         1  20   7.88                     0.78   130\n",
      "rtdl_MLP                      1  18   8.94                     0.66   133\n",
      "DeepFM                        1  20   9.76                     0.63    90\n",
      "TabNet                        1  21  10.12                     0.65   166\n",
      "DecisionTree                  1  20  10.29                     0.62   170\n",
      "STG                           1  21  10.50                     0.61   163\n",
      "MLP                           1  19  10.60                     0.62   169\n",
      "TabTransformer                1  19  10.68                     0.57   122\n",
      "LinearModel                   1  20  11.18                     0.53   166\n",
      "KNN                           1  21  11.82                     0.55   163\n",
      "VIME                          1  20  13.44                     0.40   162\n",
      "NAM                           1  21  14.51                     0.35    79\n",
      "\n",
      "\n",
      "metric: Log Loss\n",
      "                   Log Loss_rank_mean             \\\n",
      "                                  min max   mean   \n",
      "alg_name                                           \n",
      "XGBoost                             1  15   3.88   \n",
      "CatBoost                            1  13   4.21   \n",
      "LightGBM                            1  20   6.10   \n",
      "SAINT                               1  17   6.52   \n",
      "DANet                               1  20   7.11   \n",
      "rtdl_ResNet                         1  17   7.16   \n",
      "SVM                                 1  18   7.25   \n",
      "rtdl_FTTransformer                  1  18   8.22   \n",
      "STG                                 1  20   8.31   \n",
      "RandomForest                        1  19   9.00   \n",
      "DeepFM                              1  20   9.73   \n",
      "LinearModel                         1  19   9.86   \n",
      "TabTransformer                      1  19  10.13   \n",
      "TabNet                              1  21  10.24   \n",
      "NODE                                1  19  10.28   \n",
      "rtdl_MLP                            2  19  10.90   \n",
      "MLP                                 1  18  11.14   \n",
      "VIME                                2  19  13.07   \n",
      "NAM                                 2  20  13.19   \n",
      "DecisionTree                        1  21  13.29   \n",
      "KNN                                 1  21  13.34   \n",
      "\n",
      "                   normalized_Log Loss__test_mean count  \n",
      "                                             mean        \n",
      "alg_name                                                 \n",
      "XGBoost                                      0.03   170  \n",
      "CatBoost                                     0.04   162  \n",
      "LightGBM                                     0.08   163  \n",
      "SAINT                                        0.09    77  \n",
      "DANet                                        0.08   130  \n",
      "rtdl_ResNet                                  0.09   125  \n",
      "SVM                                          0.11   143  \n",
      "rtdl_FTTransformer                           0.13    37  \n",
      "STG                                          0.14   163  \n",
      "RandomForest                                 0.16   169  \n",
      "DeepFM                                       0.34    90  \n",
      "LinearModel                                  0.23   166  \n",
      "TabTransformer                               0.24   122  \n",
      "TabNet                                       0.28   166  \n",
      "NODE                                         0.19   138  \n",
      "rtdl_MLP                                     0.32   133  \n",
      "MLP                                          0.31   169  \n",
      "VIME                                         0.39   162  \n",
      "NAM                                          0.39    79  \n",
      "DecisionTree                                 0.46   170  \n",
      "KNN                                          0.39   163  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### STEP 2: aggregate over all folds\n",
    "\n",
    "# best, worst, and average performance for each alg, over all datasets\n",
    "for metric in metric_list:\n",
    "\n",
    "    overall_ranks = tuned_agg_df_no_default.groupby(\"alg_name\").agg(\n",
    "        {\n",
    "            f\"{metric}_rank_mean\": [\"min\", \"max\", \"mean\", \"count\"],\n",
    "            f\"normalized_{metric}__test_mean\": \"mean\",\n",
    "        }\n",
    "    ).reset_index().sort_values([(f\"{metric}_rank_mean\", \"mean\")])\n",
    "\n",
    "    # format min/max rank columns to be ints\n",
    "\n",
    "    overall_ranks.loc[:, \"count\"] = overall_ranks.loc[:, (f\"{metric}_rank_mean\", \"count\")].astype(int)\n",
    "    overall_ranks.drop(columns=(f\"{metric}_rank_mean\", \"count\"), inplace=True)\n",
    "\n",
    "    # overall_ranks.loc[:, \"alg_name\"] = overall_ranks.loc[:, \"alg_name\"].apply(lambda x: \"\\rot{\" + x + \"}\")\n",
    "    overall_ranks.loc[:, (f\"{metric}_rank_mean\", \"min\")] = overall_ranks.loc[:, (f\"{metric}_rank_mean\", \"min\")].astype(int)\n",
    "    overall_ranks.loc[:, (f\"{metric}_rank_mean\", \"max\")] = overall_ranks.loc[:, (f\"{metric}_rank_mean\", \"max\")].astype(int)\n",
    "\n",
    "    overall_ranks.loc[:, (f\"{metric}_rank_mean\", \"mean\")] = overall_ranks.loc[:, (f\"{metric}_rank_mean\", \"mean\")].round(2)\n",
    "    \n",
    "    overall_ranks.loc[:, (f\"normalized_{metric}__test_mean\", \"mean\")] = overall_ranks.loc[:,(f\"normalized_{metric}__test_mean\", \"mean\")].round(2)\n",
    "\n",
    "    print(f\"metric: {metric}\")\n",
    "    final_table = overall_ranks.set_index(\"alg_name\")\n",
    "    print(final_table)\n",
    "\n",
    "    # save to csv\n",
    "    final_table.to_csv(f\"./results/rank_tables_{metric}.csv\", index=True)\n",
    "\n",
    "    # save to latex\n",
    "    final_table.to_latex(f\"./results/rank_tables_{metric}.tex\", index=True, escape=False)\n",
    "\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Log Loss_rank_mean</th>\n",
       "      <th>normalized_Log Loss__test_mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alg_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.03</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4.21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAINT</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6.52</td>\n",
       "      <td>0.09</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANet</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>7.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rtdl_ResNet</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>7.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rtdl_FTTransformer</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.13</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STG</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>8.31</td>\n",
       "      <td>0.14</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepFM</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9.73</td>\n",
       "      <td>0.34</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearModel</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>9.86</td>\n",
       "      <td>0.23</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabTransformer</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>10.13</td>\n",
       "      <td>0.24</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>10.24</td>\n",
       "      <td>0.28</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NODE</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>10.28</td>\n",
       "      <td>0.19</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rtdl_MLP</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>10.90</td>\n",
       "      <td>0.32</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.31</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIME</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>13.07</td>\n",
       "      <td>0.39</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAM</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.39</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>13.29</td>\n",
       "      <td>0.46</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Log Loss_rank_mean             \\\n",
       "                                  min max   mean   \n",
       "alg_name                                           \n",
       "XGBoost                             1  15   3.88   \n",
       "CatBoost                            1  13   4.21   \n",
       "LightGBM                            1  20   6.10   \n",
       "SAINT                               1  17   6.52   \n",
       "DANet                               1  20   7.11   \n",
       "rtdl_ResNet                         1  17   7.16   \n",
       "SVM                                 1  18   7.25   \n",
       "rtdl_FTTransformer                  1  18   8.22   \n",
       "STG                                 1  20   8.31   \n",
       "RandomForest                        1  19   9.00   \n",
       "DeepFM                              1  20   9.73   \n",
       "LinearModel                         1  19   9.86   \n",
       "TabTransformer                      1  19  10.13   \n",
       "TabNet                              1  21  10.24   \n",
       "NODE                                1  19  10.28   \n",
       "rtdl_MLP                            2  19  10.90   \n",
       "MLP                                 1  18  11.14   \n",
       "VIME                                2  19  13.07   \n",
       "NAM                                 2  20  13.19   \n",
       "DecisionTree                        1  21  13.29   \n",
       "KNN                                 1  21  13.34   \n",
       "\n",
       "                   normalized_Log Loss__test_mean count  \n",
       "                                             mean        \n",
       "alg_name                                                 \n",
       "XGBoost                                      0.03   170  \n",
       "CatBoost                                     0.04   162  \n",
       "LightGBM                                     0.08   163  \n",
       "SAINT                                        0.09    77  \n",
       "DANet                                        0.08   130  \n",
       "rtdl_ResNet                                  0.09   125  \n",
       "SVM                                          0.11   143  \n",
       "rtdl_FTTransformer                           0.13    37  \n",
       "STG                                          0.14   163  \n",
       "RandomForest                                 0.16   169  \n",
       "DeepFM                                       0.34    90  \n",
       "LinearModel                                  0.23   166  \n",
       "TabTransformer                               0.24   122  \n",
       "TabNet                                       0.28   166  \n",
       "NODE                                         0.19   138  \n",
       "rtdl_MLP                                     0.32   133  \n",
       "MLP                                          0.31   169  \n",
       "VIME                                         0.39   162  \n",
       "NAM                                          0.39    79  \n",
       "DecisionTree                                 0.46   170  \n",
       "KNN                                          0.39   163  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNDER CONSTRUCTION: spaghetti plot - relative performance over different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'metric_rank_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'metric_rank_mean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5416/2582149904.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# which datasets to use?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult_df_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"F1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"F1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alg_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CatBoost\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult_df_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"F1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metric_rank_mean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'metric_rank_mean'"
     ]
    }
   ],
   "source": [
    "# which datasets to use?\n",
    "\n",
    "result_df_dict[\"F1\"][(result_df_dict[\"F1\"][\"alg_name\"] == \"CatBoost\") & (result_df_dict[\"F1\"][\"metric_rank_mean\"] < 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml__diabetes__37 <-- lm does well\n",
    "# openml__isolet__3481\n",
    "# openml__haberman__42\n",
    "# openml__robert__168332\n",
    "\n",
    "# openml__soybean__41 <-- rf does well\n",
    "# openml__vowel__3022\n",
    "# openml__guillermo__168337\n",
    "\n",
    "# openml__cmc__23 <-- mlp does well\n",
    "# openml__CIFAR_10__167124\n",
    "# openml__Fashion-MNIST__146825\n",
    "# openml__Internet-Advertisements__167125\t\n",
    "# openml__dilbert__168909\n",
    "\n",
    "# openml__Australian__146818 <-- catboost\n",
    "# openml__APSFailure__168868\n",
    "# openml__wdbc__9946\n",
    "# openml__pc1__3918\n",
    "# openml__eucalyptus__2079"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_datasets = [\n",
    "    \"openml__diabetes__37\",  # <-- lm does well\n",
    "    \"openml__isolet__3481\",\n",
    "    \"openml__haberman__42\",\n",
    "    # \"openml__robert__168332\", # not enough successful algs\n",
    "    \"openml__soybean__41\", #  <-- rf does well\n",
    "    \"openml__vowel__3022\",\n",
    "    # \"openml__guillermo__168337\", # not enough successful algs\n",
    "    \"openml__cmc__23\", # <-- mlp does well\n",
    "    # \"openml__CIFAR_10__167124\",  # not enough successful algs\n",
    "    # \"openml__Fashion-MNIST__146825\",  # not enough successful algs\n",
    "    \"openml__Internet-Advertisements__167125\",\t\n",
    "    \"openml__dilbert__168909\",\n",
    "    \"openml__Australian__146818\",  #<-- catboost\n",
    "    \"openml__APSFailure__168868\",\n",
    "    \"openml__wdbc__9946\",\n",
    "    \"openml__pc1__3918\",\n",
    "    \"openml__eucalyptus__2079\",\n",
    "]\n",
    "\n",
    "# names to show on the plot\n",
    "plot_dataset_names = [name[len(\"openml__\"):].split(\"_\")[0] for name in plot_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name\n",
       "openml__Devnagari-Script__167121                          5\n",
       "openml__covertype__7593                                   5\n",
       "openml__helena__168329                                    5\n",
       "openml__CIFAR_10__167124                                  6\n",
       "openml__albert__189356                                    6\n",
       "openml__guillermo__168337                                 6\n",
       "openml__Fashion-MNIST__146825                             7\n",
       "openml__riccardo__168338                                  7\n",
       "openml__robert__168332                                    7\n",
       "openml__airlines__189354                                  8\n",
       "openml__mnist_784__3573                                   8\n",
       "openml__higgs__146606                                     9\n",
       "openml__jungle_chess_2pcs_raw_endgame_complete__167119    9\n",
       "openml__numerai28.6__167120                               9\n",
       "openml__skin-segmentation__9965                           9\n",
       "openml__sylvine__168912                                   9\n",
       "Name: alg_name, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of results for each dataset\n",
    "num_alg_per_dataset = result_df_dict[\"F1\"].groupby(\"dataset_name\")[\"alg_name\"].count()\n",
    "num_alg_per_dataset[num_alg_per_dataset < 10].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there's an issue with CatBoost-openml__isolet__3481-Accuracy\n",
      "[]\n",
      "there's an issue with LightGBM-openml__dilbert__168909-Accuracy\n",
      "[]\n",
      "there's an issue with RandomForest-openml__haberman__42-Accuracy\n",
      "[]\n",
      "there's an issue with SVM-openml__soybean__41-Accuracy\n",
      "[]\n",
      "there's an issue with CatBoost-openml__isolet__3481-F1\n",
      "[]\n",
      "there's an issue with LightGBM-openml__dilbert__168909-F1\n",
      "[]\n",
      "there's an issue with RandomForest-openml__haberman__42-F1\n",
      "[]\n",
      "there's an issue with SVM-openml__soybean__41-F1\n",
      "[]\n",
      "there's an issue with CatBoost-openml__isolet__3481-Log Loss\n",
      "[]\n",
      "there's an issue with LightGBM-openml__dilbert__168909-Log Loss\n",
      "[]\n",
      "there's an issue with RandomForest-openml__haberman__42-Log Loss\n",
      "[]\n",
      "there's an issue with SVM-openml__soybean__41-Log Loss\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "plot_algs = agg_tuned_alg_perf[\"alg_name\"].unique()\n",
    "\n",
    "# gather data for the spaghetti plot\n",
    "data = dict()\n",
    "for i_metric, metric_name in enumerate(metric_list):\n",
    "    data[metric_name] = dict()\n",
    "    for alg in plot_algs:\n",
    "            data[metric_name][alg] = []\n",
    "            for dataset in plot_datasets:\n",
    "                vals = result_df_dict[metric_name].loc[(result_df_dict[metric_name][\"alg_name\"] == alg) & (result_df_dict[metric_name][\"dataset_name\"] == dataset), f\"normalized_{metric_name}__test_mean\"].values\n",
    "                if len(vals) != 1:\n",
    "                    print(f\"there's an issue with {alg}-{dataset}-{metric_name}\")\n",
    "                    print(vals)\n",
    "                    val = None\n",
    "                else:\n",
    "                    val = vals[0]\n",
    "                data[metric_name][alg].append(val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting kwargs\n",
    "\n",
    "plot_alg_map = {\n",
    "    \"XGBoost\": {\n",
    "        \"name\": \"XGBoost\",\n",
    "        \"plt-kwargs\": {\"marker\":\"x\", \"color\":\"r\", \"linestyle\":\"--\"}\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        \"name\": \"CatBoost\",\n",
    "        \"plt-kwargs\": {\"marker\":\"+\", \"color\":\"r\", \"linestyle\":\"--\"}\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        \"name\": \"LightGBM\",\n",
    "        \"plt-kwargs\": {\"marker\":\"d\", \"color\":\"r\", \"linestyle\":\"--\"}\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"name\": \"SVM\",\n",
    "        \"plt-kwargs\": {\"marker\":\"v\", \"color\":\"black\", \"linestyle\":\"-\"}\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"name\": \"KNN\",\n",
    "        \"plt-kwargs\": {\"marker\":\"^\", \"color\":\"black\", \"linestyle\":\"-\"}\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        \"name\": \"DecisionTree\",\n",
    "        \"plt-kwargs\": {\"marker\":\">\", \"color\":\"black\", \"linestyle\":\"-\"}\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"name\": \"RandomForest\",\n",
    "        \"plt-kwargs\": {\"marker\":\"P\", \"color\":\"black\", \"linestyle\":\"-\"}\n",
    "    },\n",
    "    \"LinearModel\": {\n",
    "        \"name\": \"LinearModel\",\n",
    "        \"plt-kwargs\": {\"marker\":\"<\", \"color\":\"black\", \"linestyle\":\"-\"}\n",
    "    },\n",
    "    \"TabNet\": {\n",
    "        \"name\": \"TabNet\",\n",
    "        \"plt-kwargs\": {\"marker\":\"X\", \"color\":\"b\", \"linestyle\":\":\"}\n",
    "    },\n",
    "    \"MLP\": {\n",
    "        \"name\": \"MLP\",\n",
    "        \"plt-kwargs\": {\"marker\":\"o\", \"color\":\"b\", \"linestyle\":\":\"}\n",
    "    },\n",
    "    \"VIME\": {\n",
    "        \"name\": \"VIME\",\n",
    "        \"plt-kwargs\": {\"marker\":\"P\", \"color\":\"b\", \"linestyle\":\":\"}\n",
    "    },\n",
    "}\n",
    "\n",
    "plot_algs = plot_alg_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1959/2032905693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0malg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplot_algs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "fig, ax = plt.subplots(len(metric_list), 1, sharex=True, figsize=(8, 5))\n",
    "\n",
    "for i, metric in enumerate(metric_list):\n",
    "    for alg in plot_algs:    \n",
    "        ax[i].plot(data[metric][alg], label=alg, markersize=7, **plot_alg_map[alg][\"plt-kwargs\"])\n",
    "    ax[i].set_ylabel(metric)\n",
    "\n",
    "    ax[i].set_xticks(np.arange(len(plot_dataset_names)))\n",
    "    ax[i].set_xticklabels(plot_dataset_names, rotation=-35, ha='left', rotation_mode='anchor')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.08)\n",
    "\n",
    "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 3.6), ncol=6, fontsize=\"small\")\n",
    "plt.savefig(\"./results/performance_spaghetti.pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a153426f2134bbdcd6a5df08a5e097a8efc2dea8324c648b295b251f306d0274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
